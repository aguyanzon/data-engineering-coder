{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c401e53d-ba55-4f30-b117-7ee1fbcab21d",
   "metadata": {},
   "source": [
    "# Entregable 2\n",
    "## Consigna\n",
    "El script del entregable 1 deberá adaptar datos leídos de la API y cargarlos en la tabla creada en la pre-entrega anterior en Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7bcd6e-97fb-4d2c-ba35-a50021ab82d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, lit, col, max, lag\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04168cf9-518d-428c-b08b-64597c350a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c8b346-7856-49a4-96df-19569fc6f53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Postgres and Redshift JDBCs\n",
    "driver_path = \"/home/coder/working_dir/driver_jdbc/postgresql-42.2.27.jre7.jar\"\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f'--driver-class-path {driver_path} --jars {driver_path} pyspark-shell'\n",
    "os.environ['SPARK_CLASSPATH'] = driver_path\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Conexion entre Pyspark y Redshift\") \\\n",
    "        .config(\"spark.jars\", driver_path) \\\n",
    "        .config(\"spark.executor.extraClassPath\", driver_path) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d9055fb-e10d-4a46-9fde-4e87ce89d5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046eab9-9e13-49bf-a47a-24db97bef3de",
   "metadata": {},
   "source": [
    "## Extracción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d3d8dc-1241-4d9b-ab53-ab56f06baa59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_data(symbol):\n",
    "    try:\n",
    "        url = f'https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY&symbol={symbol}&apikey={env[\"API_KEY\"]}'\n",
    "        response = requests.get(url)\n",
    "        json_data = response.json()\n",
    "\n",
    "        data_list = []\n",
    "        for date, values_dict in json_data[\"Monthly Time Series\"].items():\n",
    "            data = (date, values_dict[\"1. open\"], values_dict[\"2. high\"], values_dict[\"3. low\"], values_dict[\"4. close\"], values_dict[\"5. volume\"])\n",
    "            data_list.append(data)\n",
    "\n",
    "        # Crear el DataFrame con todos los datos\n",
    "        df = spark.createDataFrame(data_list, [\"date_from\", \"1. open\", \"2. high\", \"3. low\", \"4. close\", \"5. volume\"])\n",
    "        df = df.withColumn(\"symbol\", lit(symbol))\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error de solicitud: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0549286-00d8-4142-adb0-850168327316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_ibm = extract_data('IBM')\n",
    "data_aapl = extract_data('AAPL')\n",
    "data_tsla = extract_data('TSLA')\n",
    "data = data_ibm.union(data_aapl).union(data_tsla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e452df6-d1cd-40e0-9098-f572f0672aa2",
   "metadata": {},
   "source": [
    "## Conexión a la base de datos y creación de tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b6e2a6-a304-4376-ad61-180648d79485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to Redshift using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=env['AWS_REDSHIFT_HOST'],\n",
    "    port=env['AWS_REDSHIFT_PORT'],\n",
    "    dbname=env['AWS_REDSHIFT_DBNAME'],\n",
    "    user=env['AWS_REDSHIFT_USER'],\n",
    "    password=env['AWS_REDSHIFT_PASSWORD']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee260795-e5e3-4b5d-8863-4d3eb08648a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created!\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(f'''\n",
    "        CREATE TABLE IF NOT EXISTS {env['AWS_REDSHIFT_SCHEMA']}.{env['AWS_REDSHIFT_TABLE']} (\n",
    "            \"date_from\" VARCHAR(10),\n",
    "            \"1. open\" VARCHAR(10),\n",
    "            \"2. high\" VARCHAR(10),\n",
    "            \"3. low\" VARCHAR(10),\n",
    "            \"4. close\" VARCHAR(10), \n",
    "            \"5. volume\" VARCHAR(10),\n",
    "            symbol VARCHAR(10) distkey\n",
    "        ) sortkey(date_from);\n",
    "    ''')\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "print(\"Table created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d441bd7-4ba6-49f4-a7e7-4b75bd717852",
   "metadata": {},
   "source": [
    "## Verificación de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b0f70e-b491-41ba-9de4-3a07d319e787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame no tiene duplicados.\n"
     ]
    }
   ],
   "source": [
    "# Verificación de duplicados\n",
    "total_rows = data.count()\n",
    "distinct_rows = data.dropDuplicates().count()\n",
    "\n",
    "# Comparar la cantidad de filas antes y después de eliminar los duplicados\n",
    "if total_rows == distinct_rows:\n",
    "    print(\"El DataFrame no tiene duplicados.\")\n",
    "else:\n",
    "    print(\"El DataFrame tiene duplicados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751478d-1edc-42a2-b9ff-58e45e5d56dd",
   "metadata": {},
   "source": [
    "## Creación de columna variación mensual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a923a2-5335-42de-8490-d92cf72b2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.partitionBy('symbol').orderBy('date_from')\n",
    "data = data.withColumn('monthly variation (%)', (col('`4. close`') - lag('`4. close`').over(window_spec)) / lag('`4. close`').over(window_spec) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b892b394-2b8c-4bb2-8671-30b9c59dd65d",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1670d404-884a-4fad-9be2-8b7e78f38e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", f\"jdbc:postgresql://{env['AWS_REDSHIFT_HOST']}:{env['AWS_REDSHIFT_PORT']}/{env['AWS_REDSHIFT_DBNAME']}\") \\\n",
    "    .option(\"dbtable\", f\"{env['AWS_REDSHIFT_SCHEMA']}.{env['AWS_REDSHIFT_TABLE']}\") \\\n",
    "    .option(\"user\", env['AWS_REDSHIFT_USER']) \\\n",
    "    .option(\"password\", env['AWS_REDSHIFT_PASSWORD']) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0742f-2847-4088-9959-1f8ae376e9f2",
   "metadata": {},
   "source": [
    "## Consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df933adb-a094-4d2a-84a4-fb973ecf44f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query Redshift using Spark SQL\n",
    "query = f\"select * from {env['AWS_REDSHIFT_SCHEMA']}.{env['AWS_REDSHIFT_TABLE']} limit 10\"\n",
    "data = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", f\"jdbc:postgresql://{env['AWS_REDSHIFT_HOST']}:{env['AWS_REDSHIFT_PORT']}/{env['AWS_REDSHIFT_DBNAME']}\") \\\n",
    "    .option(\"dbtable\", f\"({query}) as tmp_table\") \\\n",
    "    .option(\"user\", env['AWS_REDSHIFT_USER']) \\\n",
    "    .option(\"password\", env['AWS_REDSHIFT_PASSWORD']) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3d205da-b2f9-45c1-b276-1e80dc060f72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_from: string (nullable = true)\n",
      " |-- 1. open: string (nullable = true)\n",
      " |-- 2. high: string (nullable = true)\n",
      " |-- 3. low: string (nullable = true)\n",
      " |-- 4. close: string (nullable = true)\n",
      " |-- 5. volume: string (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- monthly variation (%): double (nullable = true)\n",
      "\n",
      "+----------+--------+--------+--------+--------+---------+------+---------------------+\n",
      "| date_from| 1. open| 2. high|  3. low|4. close|5. volume|symbol|monthly variation (%)|\n",
      "+----------+--------+--------+--------+--------+---------+------+---------------------+\n",
      "|1999-12-31|101.0000|118.0000| 91.0600|102.8100| 84091200|  AAPL|                 null|\n",
      "|2000-01-31|104.8700|121.5000| 86.5000|103.7500|112099800|  AAPL|   0.9143079466977897|\n",
      "|2000-02-29|104.0000|119.9400| 97.0000|114.6200| 65355200|  AAPL|   10.477108433734944|\n",
      "|2000-03-31|118.5600|150.3800|114.0000|135.8100| 77663900|  AAPL|   18.487175013086716|\n",
      "|2000-04-28|135.5000|139.5000|104.8700|124.0600| 77342900|  AAPL|   -8.651792946027538|\n",
      "|2000-05-31|124.8700|126.2500| 81.7500| 84.0000| 87569200|  AAPL|   -32.29082701918426|\n",
      "|2000-06-30| 81.7500|103.9400| 50.3100| 52.3800| 89106200|  AAPL|   -37.64285714285714|\n",
      "|2000-07-31| 52.1300| 60.6300| 46.8800| 50.8100|102620900|  AAPL|   -2.997327224131348|\n",
      "|2000-08-31| 50.3100| 61.5000| 44.2500| 60.9400|100644400|  AAPL|    19.93702027160007|\n",
      "|2000-09-29| 61.3100| 64.1200| 25.3700| 25.7500|259230900|  AAPL|   -57.74532326878897|\n",
      "+----------+--------+--------+--------+--------+---------+------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n",
    "data.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
