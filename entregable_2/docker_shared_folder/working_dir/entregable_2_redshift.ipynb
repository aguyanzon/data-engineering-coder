{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c401e53d-ba55-4f30-b117-7ee1fbcab21d",
   "metadata": {},
   "source": [
    "# Entregable 2\n",
    "## Consigna\n",
    "El script del entregable 1 deberá adaptar datos leídos de la API y cargarlos en la tabla creada en la pre-entrega anterior en Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7bcd6e-97fb-4d2c-ba35-a50021ab82d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, lit, col, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7317e671-5407-4cb0-aa9e-f4a49a3d9bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c8b346-7856-49a4-96df-19569fc6f53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Postgres and Redshift JDBCs\n",
    "driver_path = \"/home/coder/working_dir/driver_jdbc/postgresql-42.2.27.jre7.jar\"\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f'--driver-class-path {driver_path} --jars {driver_path} pyspark-shell'\n",
    "os.environ['SPARK_CLASSPATH'] = driver_path\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Conexion entre Pyspark y Redshift\") \\\n",
    "        .config(\"spark.jars\", driver_path) \\\n",
    "        .config(\"spark.executor.extraClassPath\", driver_path) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d9055fb-e10d-4a46-9fde-4e87ce89d5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046eab9-9e13-49bf-a47a-24db97bef3de",
   "metadata": {},
   "source": [
    "## Extracción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d3d8dc-1241-4d9b-ab53-ab56f06baa59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_data(symbol):\n",
    "    try:\n",
    "        url = f'https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY&symbol={symbol}&apikey={env[\"API_KEY\"]}'\n",
    "        response = requests.get(url)\n",
    "        json_data = response.json()\n",
    "\n",
    "        data_list = []\n",
    "        for date, values_dict in json_data[\"Monthly Time Series\"].items():\n",
    "            data = (date, values_dict[\"1. open\"], values_dict[\"2. high\"], values_dict[\"3. low\"], values_dict[\"4. close\"], values_dict[\"5. volume\"])\n",
    "            data_list.append(data)\n",
    "\n",
    "        # Crear el DataFrame con todos los datos\n",
    "        df = spark.createDataFrame(data_list, [\"date_from\", \"1. open\", \"2. high\", \"3. low\", \"4. close\", \"5. volume\"])\n",
    "        df = df.withColumn(\"symbol\", lit(symbol))\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error de solicitud: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0549286-00d8-4142-adb0-850168327316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_ibm = extract_data('IBM')\n",
    "data_aapl = extract_data('AAPL')\n",
    "data_tsla = extract_data('TSLA')\n",
    "data = data_ibm.union(data_aapl).union(data_tsla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e452df6-d1cd-40e0-9098-f572f0672aa2",
   "metadata": {},
   "source": [
    "## Conexión a la base de datos y creación de tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b6e2a6-a304-4376-ad61-180648d79485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to Redshift using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=env['AWS_REDSHIFT_HOST'],\n",
    "    port=env['AWS_REDSHIFT_PORT'],\n",
    "    dbname=env['AWS_REDSHIFT_DBNAME'],\n",
    "    user=env['AWS_REDSHIFT_USER'],\n",
    "    password=env['AWS_REDSHIFT_PASSWORD']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee260795-e5e3-4b5d-8863-4d3eb08648a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created!\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(f'''\n",
    "        CREATE TABLE IF NOT EXISTS {env['AWS_REDSHIFT_SCHEMA']}.{env['AWS_REDSHIFT_TABLE']} (\n",
    "            \"date_from\" VARCHAR(10),\n",
    "            \"1. open\" VARCHAR(10),\n",
    "            \"2. high\" VARCHAR(10),\n",
    "            \"3. low\" VARCHAR(10),\n",
    "            \"4. close\" VARCHAR(10), \n",
    "            \"5. volume\" VARCHAR(10),\n",
    "            symbol VARCHAR(10) distkey\n",
    "        ) sortkey(date_from);\n",
    "    ''')\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "print(\"Table created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d441bd7-4ba6-49f4-a7e7-4b75bd717852",
   "metadata": {},
   "source": [
    "## Verificación de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b0f70e-b491-41ba-9de4-3a07d319e787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame no tiene duplicados.\n"
     ]
    }
   ],
   "source": [
    "# Verificación de duplicados\n",
    "total_rows = data.count()\n",
    "distinct_rows = data.dropDuplicates().count()\n",
    "\n",
    "# Comparar la cantidad de filas antes y después de eliminar los duplicados\n",
    "if total_rows == distinct_rows:\n",
    "    print(\"El DataFrame no tiene duplicados.\")\n",
    "else:\n",
    "    print(\"El DataFrame tiene duplicados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b892b394-2b8c-4bb2-8671-30b9c59dd65d",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1670d404-884a-4fad-9be2-8b7e78f38e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", f\"jdbc:postgresql://{env['AWS_REDSHIFT_HOST']}:{env['AWS_REDSHIFT_PORT']}/{env['AWS_REDSHIFT_DBNAME']}\") \\\n",
    "    .option(\"dbtable\", f\"{env['AWS_REDSHIFT_SCHEMA']}.{env['AWS_REDSHIFT_TABLE']}\") \\\n",
    "    .option(\"user\", env['AWS_REDSHIFT_USER']) \\\n",
    "    .option(\"password\", env['AWS_REDSHIFT_PASSWORD']) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0742f-2847-4088-9959-1f8ae376e9f2",
   "metadata": {},
   "source": [
    "## Consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df933adb-a094-4d2a-84a4-fb973ecf44f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query Redshift using Spark SQL\n",
    "query = f\"select distinct symbol from {env['AWS_REDSHIFT_SCHEMA']}.{env['AWS_REDSHIFT_TABLE']}\"\n",
    "data = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", f\"jdbc:postgresql://{env['AWS_REDSHIFT_HOST']}:{env['AWS_REDSHIFT_PORT']}/{env['AWS_REDSHIFT_DBNAME']}\") \\\n",
    "    .option(\"dbtable\", f\"({query}) as tmp_table\") \\\n",
    "    .option(\"user\", env['AWS_REDSHIFT_USER']) \\\n",
    "    .option(\"password\", env['AWS_REDSHIFT_PASSWORD']) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d205da-b2f9-45c1-b276-1e80dc060f72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symbol: string (nullable = true)\n",
      "\n",
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|   IBM|\n",
      "|  AAPL|\n",
      "|  TSLA|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n",
    "data.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
